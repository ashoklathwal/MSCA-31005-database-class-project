{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import codecs\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import random, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UTF8Writer = codecs.getwriter('utf8')\n",
    "sys.stdout = UTF8Writer(sys.stdout)\n",
    "url_string = \"http://api.meetup.com//\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching complete category,cities,topic_categories information using meetup.api package\n",
    "import meetup.api\n",
    "client = meetup.api.Client(api_key,overlimit_wait=True)\n",
    "a = client.GetCategories()\n",
    "#Categories\n",
    "categories_df = pd.read_json(json.dumps(a.results))\n",
    "categories_df.to_csv('categories.csv', index = False)\n",
    "#Cities\n",
    "cities = client.GetCities(country='US',state=)\n",
    "cities_df = pd.read_json(json.dumps(cities.results))\n",
    "cities_df.to_csv('cities.csv',index=False)\n",
    "#Topic_Categories\n",
    "topic_categories = client.GetTopicCategories()\n",
    "topic_catg_df = pd.read_json(json.dumps(topic_categories.results))\n",
    "topic_catg_df.to_csv('topic_categories.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read Categories File\n",
    "df = pd.read_csv('categories.csv')\n",
    "catg_id = df.id #you can also use df['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to fetch group\n",
    "def getgroups(catg_id,off_val):\n",
    "    group = client.GetGroups(category_id = catg_id,offset = off_val)\n",
    "    result = group.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create groups files for every catrgory\n",
    "for i in range(len(catg_id)):\n",
    "    groups = pd.DataFrame([])\n",
    "    for j in range(10000):\n",
    "        result = getgroups(catg_id[i],j)\n",
    "        if len(result) != 0:\n",
    "            groups = groups.append(result)\n",
    "        else:\n",
    "            break\n",
    "    groups.to_csv('groups_'+ str(catg_id[i]) +'.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Call the api\n",
    "def get_results(string, params):\n",
    "    request = requests.get(string,params=params)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetch unique groups \n",
    "cwd = os.getcwd()\n",
    "group_id_extract = pd.DataFrame([])\n",
    "dat_list = []\n",
    "for i in catg_id:\n",
    "    data = pd.read_csv(cwd+'/group_data/groups_'+str(i)+'.csv',usecols=[13,4], index_col = False, header=0)   \n",
    "    dat_list.append(data)\n",
    "group_id_extract = pd.concat(dat_list)\n",
    "group_id_new = group_id_extract[group_id_extract['country']=='US']['id']\n",
    "group_id_US = group_id_new.drop_duplicates().reset_index(drop=True)\n",
    "unique_groups = np.array(group_id_US)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to fetch members data\n",
    "def get_members( group_id, index,num_groups ):\n",
    "    result =[]\n",
    "    prev=[]\n",
    "    for offset in range(10000):\n",
    "        count = 0\n",
    "        while True:\n",
    "            params = {\"sign\":\"true\", \"key\":api_key, \"page\":200, \"offset\":offset, \"group_id\":group_id}\n",
    "            try:\n",
    "                time.sleep(0.1)\n",
    "                temp = get_results(url_string + \"2/members\", params)\n",
    "            except ValueError, ChunkedEncodingError:\n",
    "                continue\n",
    "            break\n",
    "        if len(temp['results']) != 0:\n",
    "            if prev == temp['results']:\n",
    "                value = pd.DataFrame(pd.io.json.json_normalize(result))\n",
    "                value['group_id']=[group_id] *len(value)\n",
    "                \n",
    "                value.to_csv(\"./member_data/member_\"+str(group_id)+'.csv', encoding = 'utf-8',sep=str(\",\"))\n",
    "                return None\n",
    "            result = result + temp['results']\n",
    "            sys.stdout.write('\\r' + \"Processed: \" + str(len(result)) + \" events for group number \" + str(group_id) +\\\n",
    "                             \". Progress: \"+ str(index) +'/'+str(num_groups))\n",
    "            sys.stdout.flush()\n",
    "            prev = copy.deepcopy(temp['results'])\n",
    "        else:\n",
    "            break\n",
    "    sys.stdout.write('\\r' + \" \"*150 + '\\r')\n",
    "    value = pd.DataFrame(pd.io.json.json_normalize(result))\n",
    "    value['group_id']=[group_id] *len(value)\n",
    "    value.to_csv(\"./member_data/member_\"+str(group_id)+'.csv', encoding = 'utf-8',sep=str(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetch members and extract to csv\n",
    "num_groups = len(unique_groups)\n",
    "for index, group_id in enumerate(unique_groups):\n",
    "    (get_members(group_id,index, num_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to fetch events\n",
    "def getevents(group_id,off_val):\n",
    "    event = client.GetEvents(group_id = group_id, offset = off_val)\n",
    "    result = event.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetch events and extract to csv\n",
    "events = pd.DataFrame([])\n",
    "for i in range(len(unique_groups)):\n",
    "    for j in range(10000):\n",
    "        result = getevents(unique_groups.id[i], j)\n",
    "        if len(result) != 0:\n",
    "            events = events.append(result)\n",
    "        else:\n",
    "            break\n",
    "events.to_csv('events.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to fetch venues\n",
    "def getvenues(group_id,off_val):\n",
    "    venue = client.GetVenues(group_id = group_id, offset = off_val)\n",
    "    result = venue.results\n",
    "    return result\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetch venues and extract csv\n",
    "cwd = os.getcwd()\n",
    "for index, row in data_US_idx.iteritems():\n",
    "    group_id = row\n",
    "for index, group_id in enumerate(unique_groups):\n",
    "    for offset in range(10000):\n",
    "        try: \n",
    "            return_value = getvenues(group_id,offset)\n",
    "            time.sleep(0.05)\n",
    "        except:\n",
    "            time.sleep(3610)\n",
    "            return_value = getvenues(group_id,offset)\n",
    "            print(\"Exception was raised!\")\n",
    "            pass\n",
    "        if len(return_value) > 0:\n",
    "            temp_df = pd.DataFrame(return_value)\n",
    "            temp_df['group_id'] = [group_id]* len(temp_df)\n",
    "            venues = venues.append(temp_df,ignore_index=True)\n",
    "        else:\n",
    "            break\n",
    "    if index % 100 ==0:\n",
    "        venues.to_csv(cwd+'/venue_data/venues_'+str(i)+ '_'+ str(index) + '.csv', index = False, encoding = 'utf-8')\n",
    "        venues = pd.DataFrame()\n",
    "venues.to_csv(cwd+'/venue_data/venues_final.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#List of topics_categories\n",
    "topics = ['art','spirituality','literature','business-networking','professional-networking','dance','dancing','education','fashion','Fashion Industry','movies','Watching movies','wine-and-food','wine-and-food-pairing','games','wellness','craftswap','crafts','language','Language & Culture','lgbtfriends','LGBT','community','music','outdoors','parents','pet-animals','pets','photo','photography','social','sports','Sports and Recreation','newtech','New Technology','writing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to fetch topics\n",
    "def gettopics(topic_name,off_val):\n",
    "    topics = client.GetTopics(search = topic_name,offset = off_val)\n",
    "    result = topics.results\n",
    "    RES = json_normalize(result)\n",
    "    return RES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fetch topics and extract csv\n",
    "for i in range(len(topics)):\n",
    "    topics = pd.DataFrame([])\n",
    "    for j in range(10000):\n",
    "        result = gettopics(str(topics[i]),j)\n",
    "        if len(result) != 0:\n",
    "            topics = topics.append(result)\n",
    "        else:\n",
    "            break\n",
    "    topics.to_csv('./topics_data/topic_'+ str(i) +'.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
